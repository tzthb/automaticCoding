{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tizander/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /Users/tizander/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tizander/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tizander/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (39232, 17)\n",
      "Shape of y_train: (39232,)\n",
      "Shape of X_val: (8407, 17)\n",
      "Shape of y_val: (8407,)\n",
      "Shape of X_test: (8408, 17)\n",
      "Shape of y_test: (8408,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflowjs as tfjs\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Read the data from CSV file\n",
    "try:\n",
    "    data = pd.read_csv(\"ICD10_openmed_UTF8.csv\", delimiter=\";\", encoding=\"utf-8\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please provide the correct path.\")\n",
    "    exit()\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: CSV parsing error. Check the format of your data.\")\n",
    "    exit()\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the text data\n",
    "data['processed_term'] = data['term'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['processed_term']) \n",
    "sequences = tokenizer.texts_to_sequences(data['processed_term'])\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Convert labels to numeric indices\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data[\"icd10\"])\n",
    "\n",
    "# Split the data into training, test, and validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check the shapes of the data\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_val.shape}\")\n",
    "print(f\"Shape of y_val: {y_val.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,239,552</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3621</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">467,109</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,239,552\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m263,808\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m16,512\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3621\u001b[0m)      │    \u001b[38;5;34m467,109\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,987,493</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,987,493\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,987,493</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,987,493\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 148ms/step - accuracy: 0.1096 - loss: 7.3004 - val_accuracy: 0.2096 - val_loss: 5.7925\n",
      "Epoch 2/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 151ms/step - accuracy: 0.2569 - loss: 5.4257 - val_accuracy: 0.3235 - val_loss: 4.7631\n",
      "Epoch 3/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.3736 - loss: 4.4435 - val_accuracy: 0.4511 - val_loss: 4.0662\n",
      "Epoch 4/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 145ms/step - accuracy: 0.4729 - loss: 3.7047 - val_accuracy: 0.5036 - val_loss: 3.5984\n",
      "Epoch 5/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 146ms/step - accuracy: 0.5315 - loss: 3.2240 - val_accuracy: 0.5357 - val_loss: 3.2624\n",
      "Epoch 6/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 146ms/step - accuracy: 0.5747 - loss: 2.8517 - val_accuracy: 0.5694 - val_loss: 3.0092\n",
      "Epoch 7/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 146ms/step - accuracy: 0.6096 - loss: 2.5361 - val_accuracy: 0.5863 - val_loss: 2.8053\n",
      "Epoch 8/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 146ms/step - accuracy: 0.6362 - loss: 2.2656 - val_accuracy: 0.5934 - val_loss: 2.6874\n",
      "Epoch 9/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.6548 - loss: 2.0861 - val_accuracy: 0.6093 - val_loss: 2.5527\n",
      "Epoch 10/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.6789 - loss: 1.8771 - val_accuracy: 0.6095 - val_loss: 2.4885\n",
      "Epoch 11/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.6865 - loss: 1.7499 - val_accuracy: 0.6256 - val_loss: 2.3742\n",
      "Epoch 12/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.7105 - loss: 1.6105 - val_accuracy: 0.6296 - val_loss: 2.3049\n",
      "Epoch 13/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7220 - loss: 1.5042 - val_accuracy: 0.6346 - val_loss: 2.2600\n",
      "Epoch 14/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.7382 - loss: 1.3657 - val_accuracy: 0.6341 - val_loss: 2.2244\n",
      "Epoch 15/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7486 - loss: 1.2849 - val_accuracy: 0.6360 - val_loss: 2.1739\n",
      "Epoch 16/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 150ms/step - accuracy: 0.7603 - loss: 1.1982 - val_accuracy: 0.6390 - val_loss: 2.1511\n",
      "Epoch 17/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7706 - loss: 1.1225 - val_accuracy: 0.6422 - val_loss: 2.1348\n",
      "Epoch 18/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.7711 - loss: 1.0704 - val_accuracy: 0.6409 - val_loss: 2.1269\n",
      "Epoch 19/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.7792 - loss: 1.0067 - val_accuracy: 0.6416 - val_loss: 2.1105\n",
      "Epoch 20/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7777 - loss: 0.9772 - val_accuracy: 0.6440 - val_loss: 2.1018\n",
      "Epoch 21/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7808 - loss: 0.9280 - val_accuracy: 0.6451 - val_loss: 2.0915\n",
      "Epoch 22/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.7879 - loss: 0.8906 - val_accuracy: 0.6428 - val_loss: 2.0887\n",
      "Epoch 23/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.7905 - loss: 0.8401 - val_accuracy: 0.6439 - val_loss: 2.0922\n",
      "Epoch 24/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7894 - loss: 0.8172 - val_accuracy: 0.6427 - val_loss: 2.0930\n",
      "Epoch 25/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7908 - loss: 0.7984 - val_accuracy: 0.6434 - val_loss: 2.0960\n",
      "Epoch 26/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 152ms/step - accuracy: 0.7920 - loss: 0.7695 - val_accuracy: 0.6439 - val_loss: 2.0978\n",
      "Epoch 27/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 160ms/step - accuracy: 0.7977 - loss: 0.7385 - val_accuracy: 0.6434 - val_loss: 2.1092\n",
      "Epoch 28/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 143ms/step - accuracy: 0.8006 - loss: 0.7232 - val_accuracy: 0.6383 - val_loss: 2.1137\n",
      "Epoch 29/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 149ms/step - accuracy: 0.7976 - loss: 0.7118 - val_accuracy: 0.6447 - val_loss: 2.1209\n",
      "Epoch 30/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 152ms/step - accuracy: 0.8004 - loss: 0.6926 - val_accuracy: 0.6440 - val_loss: 2.1323\n",
      "Epoch 31/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.8038 - loss: 0.6821 - val_accuracy: 0.6429 - val_loss: 2.1438\n",
      "Epoch 32/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7993 - loss: 0.6811 - val_accuracy: 0.6421 - val_loss: 2.1518\n",
      "Epoch 33/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.8070 - loss: 0.6493 - val_accuracy: 0.6441 - val_loss: 2.1551\n",
      "Epoch 34/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 154ms/step - accuracy: 0.8051 - loss: 0.6499 - val_accuracy: 0.6449 - val_loss: 2.1672\n",
      "Epoch 35/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.8062 - loss: 0.6419 - val_accuracy: 0.6428 - val_loss: 2.1852\n",
      "Epoch 36/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 143ms/step - accuracy: 0.8067 - loss: 0.6336 - val_accuracy: 0.6436 - val_loss: 2.1885\n",
      "Epoch 37/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 149ms/step - accuracy: 0.8067 - loss: 0.6303 - val_accuracy: 0.6420 - val_loss: 2.2081\n",
      "Epoch 38/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 146ms/step - accuracy: 0.8065 - loss: 0.6217 - val_accuracy: 0.6416 - val_loss: 2.2131\n",
      "Epoch 39/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 146ms/step - accuracy: 0.8094 - loss: 0.6170 - val_accuracy: 0.6440 - val_loss: 2.2196\n",
      "Epoch 40/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 150ms/step - accuracy: 0.8079 - loss: 0.6144 - val_accuracy: 0.6420 - val_loss: 2.2318\n",
      "Epoch 41/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 161ms/step - accuracy: 0.8074 - loss: 0.6161 - val_accuracy: 0.6407 - val_loss: 2.2461\n",
      "Epoch 42/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 171ms/step - accuracy: 0.8140 - loss: 0.5971 - val_accuracy: 0.6416 - val_loss: 2.2583\n",
      "Epoch 43/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 156ms/step - accuracy: 0.8132 - loss: 0.6016 - val_accuracy: 0.6421 - val_loss: 2.2712\n",
      "Epoch 44/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 156ms/step - accuracy: 0.8110 - loss: 0.5984 - val_accuracy: 0.6457 - val_loss: 2.2759\n",
      "Epoch 45/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 179ms/step - accuracy: 0.8113 - loss: 0.5971 - val_accuracy: 0.6414 - val_loss: 2.2899\n",
      "Epoch 46/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 273ms/step - accuracy: 0.8152 - loss: 0.5874 - val_accuracy: 0.6377 - val_loss: 2.2942\n",
      "Epoch 47/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 261ms/step - accuracy: 0.8116 - loss: 0.5888 - val_accuracy: 0.6407 - val_loss: 2.3077\n",
      "Epoch 48/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 260ms/step - accuracy: 0.8141 - loss: 0.5844 - val_accuracy: 0.6430 - val_loss: 2.3118\n",
      "Epoch 49/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 255ms/step - accuracy: 0.8176 - loss: 0.5757 - val_accuracy: 0.6404 - val_loss: 2.3189\n",
      "Epoch 50/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 213ms/step - accuracy: 0.8146 - loss: 0.5770 - val_accuracy: 0.6377 - val_loss: 2.3355\n",
      "Epoch 51/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 160ms/step - accuracy: 0.8132 - loss: 0.5790 - val_accuracy: 0.6398 - val_loss: 2.3448\n",
      "Epoch 52/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 256ms/step - accuracy: 0.8173 - loss: 0.5726 - val_accuracy: 0.6405 - val_loss: 2.3496\n",
      "Epoch 53/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 252ms/step - accuracy: 0.8182 - loss: 0.5743 - val_accuracy: 0.6383 - val_loss: 2.3629\n",
      "Epoch 54/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 257ms/step - accuracy: 0.8101 - loss: 0.5796 - val_accuracy: 0.6340 - val_loss: 2.3672\n",
      "Epoch 55/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 252ms/step - accuracy: 0.8172 - loss: 0.5662 - val_accuracy: 0.6409 - val_loss: 2.3814\n",
      "Epoch 56/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 248ms/step - accuracy: 0.8176 - loss: 0.5599 - val_accuracy: 0.6408 - val_loss: 2.3845\n",
      "Epoch 57/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 250ms/step - accuracy: 0.8136 - loss: 0.5663 - val_accuracy: 0.6370 - val_loss: 2.4015\n",
      "Epoch 58/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 258ms/step - accuracy: 0.8161 - loss: 0.5711 - val_accuracy: 0.6377 - val_loss: 2.3997\n",
      "Epoch 59/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 253ms/step - accuracy: 0.8133 - loss: 0.5720 - val_accuracy: 0.6377 - val_loss: 2.4132\n",
      "Epoch 60/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 255ms/step - accuracy: 0.8196 - loss: 0.5613 - val_accuracy: 0.6401 - val_loss: 2.4287\n",
      "Epoch 61/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 255ms/step - accuracy: 0.8164 - loss: 0.5605 - val_accuracy: 0.6413 - val_loss: 2.4307\n",
      "Epoch 62/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 253ms/step - accuracy: 0.8188 - loss: 0.5502 - val_accuracy: 0.6378 - val_loss: 2.4362\n",
      "Epoch 63/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 256ms/step - accuracy: 0.8180 - loss: 0.5601 - val_accuracy: 0.6367 - val_loss: 2.4404\n",
      "Epoch 64/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 254ms/step - accuracy: 0.8198 - loss: 0.5551 - val_accuracy: 0.6384 - val_loss: 2.4561\n",
      "Epoch 65/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 253ms/step - accuracy: 0.8158 - loss: 0.5658 - val_accuracy: 0.6376 - val_loss: 2.4566\n",
      "Epoch 66/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 257ms/step - accuracy: 0.8155 - loss: 0.5604 - val_accuracy: 0.6376 - val_loss: 2.4668\n",
      "Epoch 67/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 259ms/step - accuracy: 0.8164 - loss: 0.5547 - val_accuracy: 0.6346 - val_loss: 2.4791\n",
      "Epoch 68/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 258ms/step - accuracy: 0.8156 - loss: 0.5568 - val_accuracy: 0.6367 - val_loss: 2.4763\n",
      "Epoch 69/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 261ms/step - accuracy: 0.8181 - loss: 0.5515 - val_accuracy: 0.6377 - val_loss: 2.4725\n",
      "Epoch 70/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 264ms/step - accuracy: 0.8195 - loss: 0.5473 - val_accuracy: 0.6416 - val_loss: 2.4887\n",
      "Epoch 71/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 265ms/step - accuracy: 0.8194 - loss: 0.5477 - val_accuracy: 0.6396 - val_loss: 2.4928\n",
      "Epoch 72/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 256ms/step - accuracy: 0.8192 - loss: 0.5531 - val_accuracy: 0.6408 - val_loss: 2.5069\n",
      "Epoch 73/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 259ms/step - accuracy: 0.8224 - loss: 0.5500 - val_accuracy: 0.6363 - val_loss: 2.4975\n",
      "Epoch 74/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 260ms/step - accuracy: 0.8168 - loss: 0.5497 - val_accuracy: 0.6352 - val_loss: 2.5198\n",
      "Epoch 75/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 258ms/step - accuracy: 0.8199 - loss: 0.5414 - val_accuracy: 0.6398 - val_loss: 2.5163\n",
      "Epoch 76/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 262ms/step - accuracy: 0.8198 - loss: 0.5407 - val_accuracy: 0.6396 - val_loss: 2.5209\n",
      "Epoch 77/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 257ms/step - accuracy: 0.8203 - loss: 0.5461 - val_accuracy: 0.6376 - val_loss: 2.5274\n",
      "Epoch 78/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 259ms/step - accuracy: 0.8144 - loss: 0.5593 - val_accuracy: 0.6359 - val_loss: 2.5352\n",
      "Epoch 79/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 255ms/step - accuracy: 0.8188 - loss: 0.5461 - val_accuracy: 0.6361 - val_loss: 2.5495\n",
      "Epoch 80/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 252ms/step - accuracy: 0.8186 - loss: 0.5420 - val_accuracy: 0.6379 - val_loss: 2.5420\n",
      "Epoch 81/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 250ms/step - accuracy: 0.8166 - loss: 0.5518 - val_accuracy: 0.6352 - val_loss: 2.5517\n",
      "Epoch 82/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 251ms/step - accuracy: 0.8185 - loss: 0.5472 - val_accuracy: 0.6399 - val_loss: 2.5554\n",
      "Epoch 83/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 252ms/step - accuracy: 0.8188 - loss: 0.5410 - val_accuracy: 0.6355 - val_loss: 2.5615\n",
      "Epoch 84/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 250ms/step - accuracy: 0.8178 - loss: 0.5493 - val_accuracy: 0.6372 - val_loss: 2.5680\n",
      "Epoch 85/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 250ms/step - accuracy: 0.8229 - loss: 0.5384 - val_accuracy: 0.6371 - val_loss: 2.5733\n",
      "Epoch 86/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 247ms/step - accuracy: 0.8203 - loss: 0.5395 - val_accuracy: 0.6405 - val_loss: 2.5669\n",
      "Epoch 87/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 246ms/step - accuracy: 0.8177 - loss: 0.5484 - val_accuracy: 0.6373 - val_loss: 2.5875\n",
      "Epoch 88/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 248ms/step - accuracy: 0.8208 - loss: 0.5369 - val_accuracy: 0.6365 - val_loss: 2.5891\n",
      "Epoch 89/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 251ms/step - accuracy: 0.8235 - loss: 0.5361 - val_accuracy: 0.6391 - val_loss: 2.5933\n",
      "Epoch 90/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 250ms/step - accuracy: 0.8157 - loss: 0.5456 - val_accuracy: 0.6370 - val_loss: 2.5973\n",
      "Epoch 91/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 255ms/step - accuracy: 0.8208 - loss: 0.5366 - val_accuracy: 0.6378 - val_loss: 2.5972\n",
      "Epoch 92/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 248ms/step - accuracy: 0.8174 - loss: 0.5458 - val_accuracy: 0.6399 - val_loss: 2.6022\n",
      "Epoch 93/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 256ms/step - accuracy: 0.8181 - loss: 0.5428 - val_accuracy: 0.6383 - val_loss: 2.6034\n",
      "Epoch 94/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 251ms/step - accuracy: 0.8228 - loss: 0.5342 - val_accuracy: 0.6407 - val_loss: 2.6090\n",
      "Epoch 95/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 257ms/step - accuracy: 0.8234 - loss: 0.5316 - val_accuracy: 0.6392 - val_loss: 2.6116\n",
      "Epoch 96/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 256ms/step - accuracy: 0.8203 - loss: 0.5395 - val_accuracy: 0.6391 - val_loss: 2.6206\n",
      "Epoch 97/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 256ms/step - accuracy: 0.8178 - loss: 0.5428 - val_accuracy: 0.6402 - val_loss: 2.6364\n",
      "Epoch 98/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 256ms/step - accuracy: 0.8190 - loss: 0.5438 - val_accuracy: 0.6393 - val_loss: 2.6356\n",
      "Epoch 99/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 255ms/step - accuracy: 0.8184 - loss: 0.5462 - val_accuracy: 0.6354 - val_loss: 2.6315\n",
      "Epoch 100/100\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 145ms/step - accuracy: 0.8223 - loss: 0.5379 - val_accuracy: 0.6374 - val_loss: 2.6393\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6370 - loss: 2.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.587895154953003\n",
      "Test Accuracy: 0.6406993269920349\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeddra_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Convert the model to TensorFlow.js format\u001b[39;00m\n\u001b[1;32m     40\u001b[0m tfjs\u001b[38;5;241m.\u001b[39mconverters\u001b[38;5;241m.\u001b[39msave_keras_model(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfjs_meddra_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/h5py/_hl/dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[0;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 128\n",
    "num_heads = 4\n",
    "ff_dim = 128\n",
    "num_classes = len(set(y))\n",
    "max_len = X.shape[1]\n",
    "\n",
    "# Model architecture with multi-head attention and causal masking\n",
    "inputs = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)(inputs)\n",
    "attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(embedding_layer, embedding_layer)\n",
    "attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "attention_output = Dropout(0.1)(attention_output)\n",
    "ff_output = Dense(ff_dim, activation='relu')(attention_output)\n",
    "ff_output = LayerNormalization(epsilon=1e-6)(ff_output)\n",
    "ff_output = Dropout(0.1)(ff_output)\n",
    "flat_output = GlobalAveragePooling1D()(ff_output)\n",
    "outputs = Dense(num_classes, activation='softmax')(flat_output)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=128)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Save the model\n",
    "model.save('meddra_model3.h5')\n",
    "\n",
    "# Convert the model to TensorFlow.js format\n",
    "tfjs.converters.save_keras_model(model, 'tfjs_meddra_model3')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
